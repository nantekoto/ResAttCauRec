{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZAZUMA6tvgK",
    "tags": []
   },
   "source": [
    "### 1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:26:54.081841Z",
     "iopub.status.busy": "2025-03-08T12:26:54.080842Z",
     "iopub.status.idle": "2025-03-08T12:27:18.472206Z",
     "shell.execute_reply": "2025-03-08T12:27:18.472206Z",
     "shell.execute_reply.started": "2025-03-08T12:26:54.081841Z"
    },
    "id": "w1RyAcQ1ZdY0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, median_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.special\n",
    "import scipy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from itertools import chain, combinations\n",
    "\n",
    "cm = 1/2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:18.474228Z",
     "iopub.status.busy": "2025-03-08T12:27:18.474228Z",
     "iopub.status.idle": "2025-03-08T12:27:20.475731Z",
     "shell.execute_reply": "2025-03-08T12:27:20.475731Z",
     "shell.execute_reply.started": "2025-03-08T12:27:18.474228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import my_model as mm\n",
    "import my_data_preprocess as mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.476719Z",
     "iopub.status.busy": "2025-03-08T12:27:20.476719Z",
     "iopub.status.idle": "2025-03-08T12:27:20.479710Z",
     "shell.execute_reply": "2025-03-08T12:27:20.479710Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.476719Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkxU_LBcuUaY",
    "tags": []
   },
   "source": [
    "### 2 Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.545212Z",
     "iopub.status.busy": "2025-03-08T12:27:20.545212Z",
     "iopub.status.idle": "2025-03-08T12:27:20.637789Z",
     "shell.execute_reply": "2025-03-08T12:27:20.637789Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.545212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_site, labels, durations, lon_lat = mdp.get_valid_site(threshold = 1)\n",
    "var_name = mdp.get_var_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.638782Z",
     "iopub.status.busy": "2025-03-08T12:27:20.638782Z",
     "iopub.status.idle": "2025-03-08T12:27:20.645199Z",
     "shell.execute_reply": "2025-03-08T12:27:20.645199Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.638782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-PFa 6805\n"
     ]
    }
   ],
   "source": [
    "maxlen = 1\n",
    "for key in durations:\n",
    "    if len(durations[key])>maxlen:\n",
    "        maxlen = len(durations[key])\n",
    "        name = key\n",
    "\n",
    "print(name, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.646184Z",
     "iopub.status.busy": "2025-03-08T12:27:20.646184Z",
     "iopub.status.idle": "2025-03-08T12:27:20.750812Z",
     "shell.execute_reply": "2025-03-08T12:27:20.749820Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.646184Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1996-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1996-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1996-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1996-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1996-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>2014-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>2014-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>2014-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>2014-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6740 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TIMESTAMP\n",
       "199  1996-07-18\n",
       "200  1996-07-19\n",
       "201  1996-07-20\n",
       "202  1996-07-21\n",
       "203  1996-07-22\n",
       "...         ...\n",
       "6934 2014-12-26\n",
       "6935 2014-12-27\n",
       "6936 2014-12-28\n",
       "6937 2014-12-29\n",
       "6938 2014-12-30\n",
       "\n",
       "[6740 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations['BE-Vie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract era5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.765778Z",
     "iopub.status.busy": "2025-03-08T12:27:20.762614Z",
     "iopub.status.idle": "2025-03-08T12:27:20.780079Z",
     "shell.execute_reply": "2025-03-08T12:27:20.780079Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.765778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_log, std_log = mdp.get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:20.782190Z",
     "iopub.status.busy": "2025-03-08T12:27:20.782190Z",
     "iopub.status.idle": "2025-03-08T12:27:26.245266Z",
     "shell.execute_reply": "2025-03-08T12:27:26.245266Z",
     "shell.execute_reply.started": "2025-03-08T12:27:20.782190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "restart = True\n",
    "while restart:\n",
    "    restart = False\n",
    "    for site_name in valid_site:\n",
    "        t000=time.time()\n",
    "        # print(site_name, len(labels[site_name]))\n",
    "        try:\n",
    "            mdp.get_nc_one_site(site_name, grid = 10)\n",
    "            # print('***site %s saved, consuming : %.3f mins****************' % (site_name, (time.time() - t000) / 60))\n",
    "            # print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime()))\n",
    "        except Exception as e:\n",
    "            print(\"failed saving\", site_name)\n",
    "            time.sleep(10) \n",
    "            restart = True\n",
    "            break\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CCM calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T12:27:26.258330Z",
     "iopub.status.busy": "2025-03-08T12:27:26.258330Z",
     "iopub.status.idle": "2025-03-08T12:27:26.725836Z",
     "shell.execute_reply": "2025-03-08T12:27:26.725836Z",
     "shell.execute_reply.started": "2025-03-08T12:27:26.258330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_states = mdp.get_ccm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Torch dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([128, 15, 12, 10, 10]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "### one site test\n",
    "site_name = valid_site[0]\n",
    "x, y = mdp.data_read(site_name)\n",
    "train_dataset = mdp.TimeseriesDataset(x, y, seq_len=15, pre_hor = 7)\n",
    "train_loader = mdp.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "for i, [inp_data, out_fea] in enumerate(train_loader):\n",
    "    print(i, inp_data.shape, out_fea.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### all site set\n",
    "### here we extract the earliest 70% observations of all sites as train set with shuffle\n",
    "### sebsequently, we extract the next 15% observations as validation set and the last 15% observations as test set\n",
    "### seperating train, validatation, test set one site by one site and grouping them together.\n",
    "\n",
    "trainset_list = []\n",
    "valid_list = []\n",
    "testset_list = []\n",
    "for i, site_name in enumerate(valid_site):\n",
    "    x, y = mdp.data_read(site_name) \n",
    "    cell_state = cell_states[site_name]\n",
    "    train_len = int(len(y) * 0.7)\n",
    "\n",
    "    val_len = int(len(y) * 0.15)\n",
    "    \n",
    "    site_dataset = mdp.TimeseriesDataset(x, y, cell_state, seq_len=15, pre_hor = 7)\n",
    "\n",
    "    trainset_list.append( Subset(site_dataset, range(train_len)))\n",
    "    valid_list.append( Subset(site_dataset, range(train_len, train_len+val_len)))\n",
    "    testset_list.append( Subset(site_dataset, range(train_len+val_len, len(y))))\n",
    "    \n",
    "\n",
    "train_set =  ConcatDataset(trainset_list)\n",
    "valid_set =  ConcatDataset(valid_list)\n",
    "test_set =  ConcatDataset(testset_list)\n",
    "all_set = ConcatDataset([train_set, valid_set, test_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260489"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 512, shuffle = True, drop_last = False)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 512, shuffle = True, drop_last = False)\n",
    "test_loader = DataLoader(test_set, batch_size = 512, shuffle = True, drop_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(model, learn_rate=5e-4, batch_size=64, r=1, max_epoch = 50):\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    import numpy as np\n",
    "\n",
    "    criteria = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "    r = f'{type(model).__name__}-{str(r)}'\n",
    "    writer = SummaryWriter(f'log/{r}')\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    t0 = time.time()\n",
    "    print(f'Training starts {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())}, model = {r}')\n",
    "\n",
    "\n",
    "    best_valid_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for e in range(max_epoch):  # Set a high maximum epoch count\n",
    "        model.train()\n",
    "        loss_log = 0\n",
    "        for i, [x, cell_state, y] in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            x = x.to(device)\n",
    "            cell_state = cell_state.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass and compute loss\n",
    "            out = model(x, cell_state).squeeze()\n",
    "            loss = criteria(out, y)\n",
    "            loss_log += loss.item()\n",
    "\n",
    "            # Backward pass and update parameters\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        valid_loss_log = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for j, [x, cell_state, y] in enumerate(valid_loader):\n",
    "                valid_out = model(x.to(device), cell_state.to(device)).squeeze()\n",
    "                valid_loss = criteria(valid_out, y.to(device))\n",
    "                valid_loss_log += valid_loss.item()\n",
    "\n",
    "        avg_train_loss = loss_log / len(train_loader)\n",
    "        avg_valid_loss = valid_loss_log / len(valid_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/valid\", avg_valid_loss, e + 1)\n",
    "        writer.add_scalar(\"Loss/train\", avg_train_loss, e + 1)\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_valid_loss < best_valid_loss:\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "\n",
    "        # Print progress\n",
    "        elapsed_time = time.time() - t0\n",
    "        remaining_time = elapsed_time / (e + 1) * (1000 - (e + 1))  # Estimate remaining time\n",
    "        print(f'epoch {e + 1:02d} [{int(elapsed_time // 60):02d}:{int(elapsed_time % 60):02d} < {int(remaining_time // 60):02d}:{int(remaining_time % 60):02d}, {elapsed_time / (e + 1):.2f} s/it]')\n",
    "\n",
    "    # Save the final model\n",
    "    ckpt = f'checkpoint/{r}.ckpt'\n",
    "    torch.save(best_model_state, ckpt)\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512 \n",
    "learn_rate = 1e-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts 2025-04-10 17:03:11, model = ResRec-retest-0\n",
      "epoch 01 [02:32 < 124:31, 152.47 s/it]\n",
      "epoch 02 [05:04 < 121:44, 152.17 s/it]\n",
      "epoch 03 [07:36 < 119:10, 152.13 s/it]\n",
      "epoch 04 [10:08 < 116:33, 152.03 s/it]\n",
      "epoch 05 [12:40 < 114:00, 152.01 s/it]\n",
      "epoch 06 [15:11 < 111:26, 151.96 s/it]\n",
      "epoch 07 [17:43 < 108:54, 151.96 s/it]\n",
      "epoch 08 [20:15 < 106:21, 151.94 s/it]\n",
      "epoch 09 [22:47 < 103:48, 151.91 s/it]\n",
      "epoch 10 [25:18 < 101:14, 151.87 s/it]\n",
      "epoch 11 [27:50 < 98:41, 151.83 s/it]\n",
      "epoch 12 [30:21 < 96:08, 151.80 s/it]\n",
      "epoch 13 [32:53 < 93:36, 151.79 s/it]\n",
      "epoch 14 [35:25 < 91:05, 151.81 s/it]\n",
      "epoch 15 [37:57 < 88:35, 151.86 s/it]\n",
      "epoch 16 [40:30 < 86:03, 151.88 s/it]\n",
      "epoch 17 [43:00 < 83:29, 151.81 s/it]\n",
      "epoch 18 [45:31 < 80:56, 151.75 s/it]\n",
      "epoch 19 [48:02 < 78:22, 151.70 s/it]\n",
      "epoch 20 [50:32 < 75:49, 151.64 s/it]\n",
      "epoch 21 [53:03 < 73:16, 151.60 s/it]\n",
      "epoch 22 [55:34 < 70:43, 151.55 s/it]\n",
      "epoch 23 [58:04 < 68:10, 151.49 s/it]\n",
      "epoch 24 [60:34 < 65:37, 151.45 s/it]\n",
      "epoch 25 [63:05 < 63:05, 151.41 s/it]\n",
      "epoch 26 [65:35 < 60:32, 151.37 s/it]\n",
      "epoch 27 [68:06 < 58:00, 151.34 s/it]\n",
      "epoch 28 [70:36 < 55:28, 151.30 s/it]\n",
      "epoch 29 [73:06 < 52:56, 151.27 s/it]\n",
      "epoch 30 [75:37 < 50:24, 151.24 s/it]\n",
      "epoch 31 [78:07 < 47:53, 151.22 s/it]\n",
      "epoch 32 [80:37 < 45:21, 151.18 s/it]\n",
      "epoch 33 [83:08 < 42:49, 151.16 s/it]\n",
      "epoch 34 [85:38 < 40:18, 151.13 s/it]\n",
      "epoch 35 [88:08 < 37:46, 151.09 s/it]\n",
      "epoch 36 [90:38 < 35:14, 151.06 s/it]\n",
      "epoch 37 [93:08 < 32:43, 151.03 s/it]\n",
      "epoch 38 [95:38 < 30:12, 151.01 s/it]\n",
      "epoch 39 [98:08 < 27:40, 150.98 s/it]\n",
      "epoch 40 [100:37 < 25:09, 150.95 s/it]\n",
      "epoch 41 [103:07 < 22:38, 150.93 s/it]\n",
      "epoch 42 [105:37 < 20:07, 150.90 s/it]\n",
      "epoch 43 [108:07 < 17:36, 150.87 s/it]\n",
      "epoch 44 [110:37 < 15:05, 150.85 s/it]\n",
      "epoch 45 [113:07 < 12:34, 150.82 s/it]\n",
      "epoch 46 [115:36 < 10:03, 150.80 s/it]\n",
      "epoch 47 [118:06 < 07:32, 150.78 s/it]\n",
      "epoch 48 [120:36 < 05:01, 150.75 s/it]\n",
      "epoch 49 [123:07 < 02:30, 150.76 s/it]\n",
      "epoch 50 [125:38 < 00:00, 150.76 s/it]\n",
      "Training starts 2025-04-10 19:08:49, model = ResRec-retest-1\n",
      "epoch 01 [02:31 < 124:06, 151.96 s/it]\n",
      "epoch 02 [05:03 < 121:31, 151.91 s/it]\n",
      "epoch 03 [07:35 < 118:57, 151.87 s/it]\n",
      "epoch 04 [10:07 < 116:29, 151.95 s/it]\n",
      "epoch 05 [12:39 < 113:55, 151.90 s/it]\n",
      "epoch 06 [15:11 < 111:23, 151.89 s/it]\n",
      "epoch 07 [17:43 < 108:49, 151.86 s/it]\n",
      "epoch 08 [20:14 < 106:16, 151.82 s/it]\n",
      "epoch 09 [22:45 < 103:42, 151.77 s/it]\n",
      "epoch 10 [25:17 < 101:10, 151.77 s/it]\n",
      "epoch 11 [27:49 < 98:38, 151.75 s/it]\n",
      "epoch 12 [30:20 < 96:05, 151.72 s/it]\n",
      "epoch 13 [32:51 < 93:32, 151.69 s/it]\n",
      "epoch 14 [35:23 < 91:00, 151.67 s/it]\n",
      "epoch 15 [37:54 < 88:27, 151.65 s/it]\n",
      "epoch 16 [40:26 < 85:55, 151.64 s/it]\n",
      "epoch 17 [42:57 < 83:23, 151.62 s/it]\n",
      "epoch 18 [45:56 < 81:39, 153.12 s/it]\n",
      "epoch 19 [50:01 < 81:37, 157.98 s/it]\n",
      "epoch 20 [53:50 < 80:46, 161.54 s/it]\n",
      "epoch 21 [58:34 < 80:53, 167.36 s/it]\n",
      "epoch 22 [62:45 < 79:52, 171.17 s/it]\n",
      "epoch 23 [66:52 < 78:30, 174.45 s/it]\n",
      "epoch 24 [70:16 < 76:07, 175.67 s/it]\n",
      "epoch 25 [72:49 < 72:49, 174.80 s/it]\n",
      "epoch 26 [75:22 < 69:35, 173.96 s/it]\n",
      "epoch 27 [77:54 < 66:22, 173.15 s/it]\n",
      "epoch 28 [80:27 < 63:12, 172.40 s/it]\n",
      "epoch 29 [82:58 < 60:05, 171.68 s/it]\n",
      "epoch 30 [85:30 < 57:00, 171.03 s/it]\n",
      "epoch 31 [88:02 < 53:57, 170.41 s/it]\n",
      "epoch 32 [90:34 < 50:56, 169.81 s/it]\n",
      "epoch 33 [93:05 < 47:57, 169.26 s/it]\n",
      "epoch 34 [95:36 < 44:59, 168.73 s/it]\n",
      "epoch 35 [98:07 < 42:03, 168.22 s/it]\n",
      "epoch 36 [100:38 < 39:08, 167.75 s/it]\n",
      "epoch 37 [103:10 < 36:15, 167.31 s/it]\n",
      "epoch 38 [105:41 < 33:22, 166.88 s/it]\n",
      "epoch 39 [108:11 < 30:30, 166.45 s/it]\n",
      "epoch 40 [110:41 < 27:40, 166.05 s/it]\n",
      "epoch 41 [113:12 < 24:50, 165.66 s/it]\n",
      "epoch 42 [115:43 < 22:02, 165.32 s/it]\n",
      "epoch 43 [118:13 < 19:14, 164.97 s/it]\n",
      "epoch 44 [120:43 < 16:27, 164.62 s/it]\n",
      "epoch 45 [123:13 < 13:41, 164.30 s/it]\n",
      "epoch 46 [125:44 < 10:56, 164.00 s/it]\n",
      "epoch 47 [128:14 < 08:11, 163.71 s/it]\n",
      "epoch 48 [130:44 < 05:26, 163.43 s/it]\n",
      "epoch 49 [133:14 < 02:43, 163.15 s/it]\n",
      "epoch 50 [135:44 < 00:00, 162.89 s/it]\n",
      "Training starts 2025-04-10 21:24:34, model = ResRec-retest-2\n",
      "epoch 01 [02:31 < 123:59, 151.83 s/it]\n",
      "epoch 02 [05:03 < 121:17, 151.61 s/it]\n",
      "epoch 03 [07:34 < 118:42, 151.54 s/it]\n",
      "epoch 04 [10:05 < 116:06, 151.44 s/it]\n",
      "epoch 05 [12:37 < 113:38, 151.52 s/it]\n",
      "epoch 06 [15:09 < 111:06, 151.52 s/it]\n",
      "epoch 07 [17:40 < 108:34, 151.51 s/it]\n",
      "epoch 08 [20:11 < 106:02, 151.48 s/it]\n",
      "epoch 09 [22:43 < 103:30, 151.49 s/it]\n",
      "epoch 10 [25:14 < 100:58, 151.47 s/it]\n",
      "epoch 11 [27:46 < 98:27, 151.47 s/it]\n",
      "epoch 12 [30:17 < 95:55, 151.45 s/it]\n",
      "epoch 13 [32:48 < 93:22, 151.43 s/it]\n",
      "epoch 14 [35:19 < 90:50, 151.39 s/it]\n",
      "epoch 15 [37:50 < 88:18, 151.38 s/it]\n",
      "epoch 16 [40:21 < 85:45, 151.35 s/it]\n",
      "epoch 17 [42:52 < 83:14, 151.34 s/it]\n",
      "epoch 18 [45:23 < 80:41, 151.30 s/it]\n",
      "epoch 19 [47:54 < 78:09, 151.28 s/it]\n",
      "epoch 20 [50:26 < 75:39, 151.31 s/it]\n",
      "epoch 21 [52:58 < 73:08, 151.34 s/it]\n",
      "epoch 22 [55:29 < 70:37, 151.33 s/it]\n",
      "epoch 23 [58:01 < 68:06, 151.35 s/it]\n",
      "epoch 24 [60:33 < 65:35, 151.38 s/it]\n",
      "epoch 25 [63:04 < 63:04, 151.39 s/it]\n",
      "epoch 26 [65:36 < 60:33, 151.41 s/it]\n",
      "epoch 27 [68:08 < 58:02, 151.42 s/it]\n",
      "epoch 28 [70:40 < 55:31, 151.43 s/it]\n",
      "epoch 29 [73:12 < 53:00, 151.46 s/it]\n",
      "epoch 30 [75:42 < 50:28, 151.43 s/it]\n",
      "epoch 31 [78:14 < 47:57, 151.44 s/it]\n",
      "epoch 32 [81:47 < 46:00, 153.34 s/it]\n",
      "epoch 33 [85:31 < 44:03, 155.49 s/it]\n",
      "epoch 34 [89:14 < 41:59, 157.49 s/it]\n",
      "epoch 35 [92:51 < 39:47, 159.18 s/it]\n",
      "epoch 36 [96:41 < 37:36, 161.16 s/it]\n",
      "epoch 37 [100:36 < 35:21, 163.16 s/it]\n",
      "epoch 38 [104:32 < 33:00, 165.07 s/it]\n",
      "epoch 39 [108:15 < 30:32, 166.56 s/it]\n",
      "epoch 40 [111:42 < 27:55, 167.55 s/it]\n",
      "epoch 41 [115:39 < 25:23, 169.27 s/it]\n",
      "epoch 42 [119:14 < 22:42, 170.34 s/it]\n",
      "epoch 43 [123:00 < 20:01, 171.63 s/it]\n",
      "epoch 44 [126:40 < 17:16, 172.74 s/it]\n",
      "epoch 45 [130:15 < 14:28, 173.67 s/it]\n",
      "epoch 46 [133:51 < 11:38, 174.60 s/it]\n",
      "epoch 47 [137:39 < 08:47, 175.73 s/it]\n",
      "epoch 48 [141:15 < 05:53, 176.57 s/it]\n",
      "epoch 49 [145:01 < 02:57, 177.58 s/it]\n",
      "epoch 50 [148:40 < 00:00, 178.41 s/it]\n",
      "Training starts 2025-04-10 23:53:15, model = ResRec-retest-3\n",
      "epoch 01 [03:40 < 179:59, 220.40 s/it]\n",
      "epoch 02 [07:27 < 178:59, 223.73 s/it]\n",
      "epoch 03 [11:09 < 174:44, 223.07 s/it]\n",
      "epoch 04 [14:50 < 170:36, 222.54 s/it]\n",
      "epoch 05 [18:36 < 167:25, 223.23 s/it]\n",
      "epoch 06 [22:14 < 163:09, 222.50 s/it]\n",
      "epoch 07 [25:58 < 159:36, 222.70 s/it]\n",
      "epoch 08 [29:47 < 156:25, 223.47 s/it]\n",
      "epoch 09 [33:26 < 152:22, 222.98 s/it]\n",
      "epoch 10 [37:10 < 148:43, 223.10 s/it]\n",
      "epoch 11 [40:43 < 144:21, 222.09 s/it]\n",
      "epoch 12 [44:17 < 140:16, 221.48 s/it]\n",
      "epoch 13 [47:58 < 136:32, 221.43 s/it]\n",
      "epoch 14 [51:39 < 132:50, 221.39 s/it]\n",
      "epoch 15 [55:11 < 128:47, 220.79 s/it]\n",
      "epoch 16 [58:49 < 124:59, 220.58 s/it]\n",
      "epoch 17 [62:35 < 121:30, 220.93 s/it]\n",
      "epoch 18 [66:18 < 117:52, 221.03 s/it]\n",
      "epoch 19 [70:07 < 114:24, 221.42 s/it]\n",
      "epoch 20 [73:42 < 110:33, 221.13 s/it]\n",
      "epoch 21 [77:13 < 106:39, 220.67 s/it]\n",
      "epoch 22 [80:53 < 102:56, 220.59 s/it]\n",
      "epoch 23 [84:36 < 99:19, 220.72 s/it]\n",
      "epoch 24 [88:01 < 95:21, 220.07 s/it]\n",
      "epoch 25 [91:47 < 91:47, 220.28 s/it]\n",
      "epoch 26 [95:20 < 88:00, 220.03 s/it]\n",
      "epoch 27 [98:55 < 84:16, 219.84 s/it]\n",
      "epoch 28 [102:39 < 80:39, 219.97 s/it]\n",
      "epoch 29 [106:18 < 76:58, 219.94 s/it]\n",
      "epoch 30 [109:56 < 73:17, 219.89 s/it]\n",
      "epoch 31 [113:36 < 69:37, 219.89 s/it]\n",
      "epoch 32 [117:15 < 65:57, 219.87 s/it]\n",
      "epoch 33 [120:53 < 62:16, 219.79 s/it]\n",
      "epoch 34 [124:34 < 58:37, 219.84 s/it]\n",
      "epoch 35 [128:06 < 54:54, 219.60 s/it]\n",
      "epoch 36 [131:40 < 51:12, 219.46 s/it]\n",
      "epoch 37 [135:19 < 47:32, 219.44 s/it]\n",
      "epoch 38 [138:57 < 43:52, 219.40 s/it]\n",
      "epoch 39 [142:43 < 40:15, 219.58 s/it]\n",
      "epoch 40 [146:18 < 36:34, 219.47 s/it]\n",
      "epoch 41 [149:54 < 32:54, 219.37 s/it]\n",
      "epoch 42 [153:31 < 29:14, 219.33 s/it]\n",
      "epoch 43 [157:08 < 25:34, 219.26 s/it]\n",
      "epoch 44 [160:43 < 21:55, 219.17 s/it]\n",
      "epoch 45 [164:27 < 18:16, 219.28 s/it]\n",
      "epoch 46 [168:02 < 14:36, 219.18 s/it]\n",
      "epoch 47 [171:41 < 10:57, 219.18 s/it]\n",
      "epoch 48 [175:25 < 07:18, 219.28 s/it]\n",
      "epoch 49 [179:04 < 03:39, 219.28 s/it]\n",
      "epoch 50 [182:48 < 00:00, 219.36 s/it]\n",
      "Training starts 2025-04-11 02:56:03, model = ResRec-retest-4\n",
      "epoch 01 [03:50 < 188:06, 230.34 s/it]\n",
      "epoch 02 [07:40 < 184:09, 230.19 s/it]\n",
      "epoch 03 [11:19 < 177:27, 226.55 s/it]\n",
      "epoch 04 [14:59 < 172:27, 224.95 s/it]\n",
      "epoch 05 [18:40 < 168:05, 224.12 s/it]\n",
      "epoch 06 [22:15 < 163:15, 222.63 s/it]\n",
      "epoch 07 [25:51 < 158:51, 221.66 s/it]\n",
      "epoch 08 [29:31 < 154:59, 221.41 s/it]\n",
      "epoch 09 [33:11 < 151:12, 221.29 s/it]\n",
      "epoch 10 [36:56 < 147:46, 221.65 s/it]\n",
      "epoch 11 [40:37 < 144:00, 221.55 s/it]\n",
      "epoch 12 [44:20 < 140:25, 221.72 s/it]\n",
      "epoch 13 [48:00 < 136:37, 221.55 s/it]\n",
      "epoch 14 [51:50 < 133:18, 222.18 s/it]\n",
      "epoch 15 [55:39 < 129:53, 222.67 s/it]\n",
      "epoch 16 [59:27 < 126:20, 222.97 s/it]\n",
      "epoch 17 [63:08 < 122:34, 222.87 s/it]\n",
      "epoch 18 [66:51 < 118:52, 222.89 s/it]\n",
      "epoch 19 [70:36 < 115:12, 223.00 s/it]\n",
      "epoch 20 [74:16 < 111:24, 222.82 s/it]\n",
      "epoch 21 [78:03 < 107:47, 223.03 s/it]\n",
      "epoch 22 [81:35 < 103:51, 222.54 s/it]\n",
      "epoch 23 [85:16 < 100:06, 222.47 s/it]\n",
      "epoch 24 [88:57 < 96:22, 222.40 s/it]\n",
      "epoch 25 [92:45 < 92:45, 222.63 s/it]\n",
      "epoch 26 [96:26 < 89:01, 222.56 s/it]\n",
      "epoch 27 [100:06 < 85:16, 222.46 s/it]\n",
      "epoch 28 [103:44 < 81:30, 222.32 s/it]\n",
      "epoch 29 [107:28 < 77:49, 222.38 s/it]\n",
      "epoch 30 [111:18 < 74:12, 222.62 s/it]\n",
      "epoch 31 [114:48 < 70:21, 222.20 s/it]\n",
      "epoch 32 [118:35 < 66:42, 222.36 s/it]\n",
      "epoch 33 [122:13 < 62:57, 222.23 s/it]\n",
      "epoch 34 [125:50 < 59:12, 222.06 s/it]\n",
      "epoch 35 [129:29 < 55:29, 221.98 s/it]\n",
      "epoch 36 [133:12 < 51:48, 222.00 s/it]\n",
      "epoch 37 [136:57 < 48:07, 222.09 s/it]\n",
      "epoch 38 [140:38 < 44:24, 222.07 s/it]\n",
      "epoch 39 [144:22 < 40:43, 222.11 s/it]\n",
      "epoch 40 [148:03 < 37:00, 222.09 s/it]\n",
      "epoch 41 [151:41 < 33:17, 221.98 s/it]\n",
      "epoch 42 [155:22 < 29:35, 221.97 s/it]\n",
      "epoch 43 [159:06 < 25:54, 222.01 s/it]\n",
      "epoch 44 [162:49 < 22:12, 222.04 s/it]\n",
      "epoch 45 [166:25 < 18:29, 221.90 s/it]\n",
      "epoch 46 [170:14 < 14:48, 222.06 s/it]\n",
      "epoch 47 [173:55 < 11:06, 222.04 s/it]\n",
      "epoch 48 [177:27 < 07:23, 221.83 s/it]\n",
      "epoch 49 [181:05 < 03:41, 221.74 s/it]\n",
      "epoch 50 [184:36 < 00:00, 221.52 s/it]\n"
     ]
    }
   ],
   "source": [
    "for m in range(10):\n",
    "    model = mm.ResRec().to(device)\n",
    "    # model.load_state_dict(torch.load('checkpoint/ResAttCauRec512-1e-4.ckpt'))\n",
    "    my_train(model = model, learn_rate = learn_rate, batch_size = batch_size, r = 'retest-'+str(m), max_epoch = 50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "ResAttCauRec                                            [512, 1]                  --\n",
       "â”œâ”€ResAttNet: 1-1                                        [7680, 12]                693,720\n",
       "â”œâ”€CauRecNet: 1-2                                        [512, 1]                  146,241\n",
       "=========================================================================================================\n",
       "Total params: 839,961\n",
       "Trainable params: 839,961\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 327.43\n",
       "=========================================================================================================\n",
       "Input size (MB): 36.86\n",
       "Forward/backward pass size (MB): 5980.27\n",
       "Params size (MB): 3.36\n",
       "Estimated Total Size (MB): 6020.49\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cell_state_in(cell_state.to(device))\n",
    "summary(model, input_data = b.to(device), depth = 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HZAZUMA6tvgK"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
